{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 101\n",
    "### PARTE 2.3 - Modelos Redes Neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contenido\n",
    "- [Modelado](#modelos)\n",
    "\n",
    "    - [**2.3.1 Glounts Deep Ar**](#1)\n",
    "        - [Definicion del modelo](#def)\n",
    "        - [Modelado con variable exogena](#exo)\n",
    "        - [Comparacion de Resultados](#1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import funciones_utiles\n",
    "from funciones_utiles import DataPrep, Metrics, guardar_metricas\n",
    "\n",
    "import time\n",
    "time.clock = time.time\n",
    "\n",
    "from gluonts.dataset.pandas import PandasDataset\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.torch.model.deepar import DeepAREstimator\n",
    "from gluonts.torch.distributions import NegativeBinomialOutput\n",
    "from gluonts.evaluation import make_evaluation_predictions\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from dash import Dash, dcc, html, Input, Output\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import dash_bootstrap_components as dbc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Importamos los df__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_tbl= pd.read_csv('Data/Modelado/comparison_tbl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>impo_1</td>\n",
       "      <td>1950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-13</td>\n",
       "      <td>impo_1</td>\n",
       "      <td>2402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-20</td>\n",
       "      <td>impo_1</td>\n",
       "      <td>2782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-27</td>\n",
       "      <td>impo_1</td>\n",
       "      <td>3263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-02-03</td>\n",
       "      <td>impo_1</td>\n",
       "      <td>3843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ds unique_id     y\n",
       "0 2019-01-06    impo_1  1950\n",
       "1 2019-01-13    impo_1  2402\n",
       "2 2019-01-20    impo_1  2782\n",
       "3 2019-01-27    impo_1  3263\n",
       "4 2019-02-03    impo_1  3843"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= DataPrep().unificar_df()\n",
    "df['y']=df['y'].astype(int)\n",
    "df['ds']= pd.to_datetime(df['ds'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ds', 'unique_id', 'y'], dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Glounts Deep Ar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Definimos el set de train y test__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.loc[df['ds'] < '2022-11-01']\n",
    "valid = df.loc[df['ds'] >= '2022-11-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = PandasDataset.from_long_dataframe(train,\n",
    "                                             target='y',\n",
    "                                             item_id='unique_id', \n",
    "                                             timestamp='ds',\n",
    "                                             freq='W')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Definicion del modelo DeepAr__\n",
    "\n",
    "La distribucion por default de DeepAR es un distribucion t-student, pero para modelar los datos es preferible que sea una Negative Binomial ya que permite obtener valores pertenecientes a los Reales Positivos, y no predicciones negativas como ocurre con la distribucion por deafault. Esta informacion es conocidad gracias al domain knowledge que no es posible que hayan valores de kilos negativos sino que pueden tomar valores 0 o positivos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bravo15\\anaconda3\\envs\\modelling-torch\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:108: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\n",
      "\n",
      "  | Name  | Type        | Params | In sizes | Out sizes   \n",
      "----------------------------------------------------------------\n",
      "0 | model | DeepARModel | 50.0 K | ?        | [1, 100, 10]\n",
      "----------------------------------------------------------------\n",
      "50.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "50.0 K    Total params\n",
      "0.200     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5289a4aecdd1423a82938419f4b9bbe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 20.82733 (best 20.82733), saving model to 'c:\\\\Users\\\\Bravo15\\\\Desktop\\\\raico\\\\Proyecto final\\\\Project_Raiconet_101\\\\lightning_logs\\\\version_174\\\\checkpoints\\\\epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 12.25746 (best 12.25746), saving model to 'c:\\\\Users\\\\Bravo15\\\\Desktop\\\\raico\\\\Proyecto final\\\\Project_Raiconet_101\\\\lightning_logs\\\\version_174\\\\checkpoints\\\\epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' was not in top 1\n",
      "Epoch 3, global step 200: 'train_loss' was not in top 1\n",
      "Epoch 4, global step 250: 'train_loss' was not in top 1\n",
      "Epoch 5, global step 300: 'train_loss' was not in top 1\n",
      "Epoch 6, global step 350: 'train_loss' was not in top 1\n",
      "Epoch 7, global step 400: 'train_loss' was not in top 1\n",
      "Epoch 8, global step 450: 'train_loss' was not in top 1\n",
      "Epoch 9, global step 500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "tic = time.clock()\n",
    "estimator = DeepAREstimator(freq='W', #la frecuencia de los datos es semanal por lo que el modelo debe ser semanal tambien\n",
    "                            context_length=10, # el modelo va a usar las ultimas 10 semanas para predecir las siguientes 10, window de 10\n",
    "                            prediction_length=10, # va a predecir las proximas 10 semanas \n",
    "                            num_layers=4, #el modelo posee tres capas con un default de 40 nodos por capa \n",
    "                            dropout_rate= 0.2, #seteo de 20% de las units en una layer en cero de forma random\n",
    "                            trainer_kwargs={ 'max_epochs':10},#210 epochs\n",
    "                            distr_output= NegativeBinomialOutput()) #el default es Distribucion t-student, pero al usar negative binomial permite que las predicciones no tomen valores negativos\n",
    "                        \n",
    "predictor = estimator.train(train_ds, num_workers= 2)\n",
    "\n",
    "toc =  time.clock() #frenamos el cronometro y a continuacion creamos la variable que guarda el tiempo transcurrido desde que empezo a correr el modelo hasta q termino\n",
    "exetime = '{0:.4f}'.format(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7921637231899379"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = list(predictor.predict(train_ds))\n",
    "\n",
    "all_preds = list()\n",
    "for item in pred:\n",
    "    unique_id = item.item_id\n",
    "    p = item.samples.mean(axis=0)\n",
    "    p10 = np.percentile(item.samples, 10, axis=0)\n",
    "    p90 = np.percentile(item.samples, 90, axis=0)\n",
    "    p25 = np.percentile(item.samples, 25, axis=0)\n",
    "    p75 = np.percentile(item.samples, 75, axis=0)\n",
    "    dates = pd.date_range(start=item.start_date.to_timestamp(), periods=len(p), freq='W')\n",
    "    family_pred = pd.DataFrame({'ds': dates, \n",
    "                                'unique_id': unique_id,\n",
    "                                'pred': p,\n",
    "                                'p25': p25,\n",
    "                                'p75': p75,\n",
    "                                'p10': p10, \n",
    "                                'p90': p90})\n",
    "    all_preds += [family_pred]\n",
    "all_preds = pd.concat(all_preds, ignore_index=True)\n",
    "\n",
    "all_preds = all_preds.merge(valid, on=['ds', 'unique_id'], how='left')\n",
    "\n",
    "all_preds.dropna(inplace=True)\n",
    "\n",
    "Metrics(all_preds['y'], all_preds['pred']).calculate_smape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>pred</th>\n",
       "      <th>p25</th>\n",
       "      <th>p75</th>\n",
       "      <th>p10</th>\n",
       "      <th>p90</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-11-06</td>\n",
       "      <td>expo_1</td>\n",
       "      <td>1906.540039</td>\n",
       "      <td>445.25</td>\n",
       "      <td>2785.00</td>\n",
       "      <td>160.7</td>\n",
       "      <td>3984.2</td>\n",
       "      <td>2720.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-11-13</td>\n",
       "      <td>expo_1</td>\n",
       "      <td>1914.739990</td>\n",
       "      <td>420.25</td>\n",
       "      <td>2872.75</td>\n",
       "      <td>133.5</td>\n",
       "      <td>4663.5</td>\n",
       "      <td>290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-11-20</td>\n",
       "      <td>expo_1</td>\n",
       "      <td>1741.180054</td>\n",
       "      <td>362.50</td>\n",
       "      <td>2422.50</td>\n",
       "      <td>106.8</td>\n",
       "      <td>3980.9</td>\n",
       "      <td>906.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-11-27</td>\n",
       "      <td>expo_1</td>\n",
       "      <td>1564.349976</td>\n",
       "      <td>397.25</td>\n",
       "      <td>2251.75</td>\n",
       "      <td>130.8</td>\n",
       "      <td>3542.0</td>\n",
       "      <td>2408.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-04</td>\n",
       "      <td>expo_1</td>\n",
       "      <td>1753.459961</td>\n",
       "      <td>356.75</td>\n",
       "      <td>2635.50</td>\n",
       "      <td>76.6</td>\n",
       "      <td>3607.9</td>\n",
       "      <td>326.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2022-12-04</td>\n",
       "      <td>impo_7</td>\n",
       "      <td>451.109985</td>\n",
       "      <td>118.00</td>\n",
       "      <td>631.75</td>\n",
       "      <td>49.7</td>\n",
       "      <td>1127.9</td>\n",
       "      <td>278.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2022-12-11</td>\n",
       "      <td>impo_7</td>\n",
       "      <td>545.140015</td>\n",
       "      <td>149.50</td>\n",
       "      <td>678.75</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1299.1</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2022-12-18</td>\n",
       "      <td>impo_7</td>\n",
       "      <td>594.190002</td>\n",
       "      <td>149.50</td>\n",
       "      <td>842.25</td>\n",
       "      <td>39.7</td>\n",
       "      <td>1559.7</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2022-12-25</td>\n",
       "      <td>impo_7</td>\n",
       "      <td>508.119995</td>\n",
       "      <td>109.00</td>\n",
       "      <td>761.75</td>\n",
       "      <td>42.5</td>\n",
       "      <td>1262.5</td>\n",
       "      <td>409.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>impo_7</td>\n",
       "      <td>495.390015</td>\n",
       "      <td>130.75</td>\n",
       "      <td>733.75</td>\n",
       "      <td>61.1</td>\n",
       "      <td>1078.2</td>\n",
       "      <td>201.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ds unique_id         pred     p25      p75    p10     p90       y\n",
       "0   2022-11-06    expo_1  1906.540039  445.25  2785.00  160.7  3984.2  2720.0\n",
       "1   2022-11-13    expo_1  1914.739990  420.25  2872.75  133.5  4663.5   290.0\n",
       "2   2022-11-20    expo_1  1741.180054  362.50  2422.50  106.8  3980.9   906.0\n",
       "3   2022-11-27    expo_1  1564.349976  397.25  2251.75  130.8  3542.0  2408.0\n",
       "4   2022-12-04    expo_1  1753.459961  356.75  2635.50   76.6  3607.9   326.0\n",
       "..         ...       ...          ...     ...      ...    ...     ...     ...\n",
       "114 2022-12-04    impo_7   451.109985  118.00   631.75   49.7  1127.9   278.0\n",
       "115 2022-12-11    impo_7   545.140015  149.50   678.75   39.0  1299.1   182.0\n",
       "116 2022-12-18    impo_7   594.190002  149.50   842.25   39.7  1559.7   260.0\n",
       "117 2022-12-25    impo_7   508.119995  109.00   761.75   42.5  1262.5   409.0\n",
       "118 2023-01-01    impo_7   495.390015  130.75   733.75   61.1  1078.2   201.0\n",
       "\n",
       "[104 rows x 8 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Resultados Obtenidos: Deep AR__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8080/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x290ba1fe260>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "app = Dash(external_stylesheets=[dbc.themes.SLATE])\n",
    "\n",
    "\n",
    "\n",
    "dropdown = dcc.Dropdown(\n",
    "    id=\"ticker\",\n",
    "    options=[{\"label\": unique_id, \"value\": unique_id} for unique_id in df[\"unique_id\"].unique()],\n",
    "    value=\"impo_1\",\n",
    "    clearable=False, \n",
    "    style={'background-color': 'grey'}\n",
    ")\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H4('Deep AR Resultados'),\n",
    "    html.P(\"Seleccionar motivo:\"),\n",
    "    dropdown,\n",
    "    dcc.Graph(id=\"time-series-chart\"),\n",
    "])\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"time-series-chart\", \"figure\"), \n",
    "    Input(\"ticker\", \"value\"))\n",
    "\n",
    "def display_time_series(ticker):\n",
    "    df_pivot = df.pivot(index='ds', columns='unique_id', values='y')\n",
    "    df_pivot = df_pivot.reset_index()\n",
    "    df_pivot = df_pivot.fillna(0)\n",
    "    \n",
    "    fig = px.line(df_pivot, x='ds', y=ticker, title=ticker, template='plotly_dark')\n",
    "    fig.update_layout(plot_bgcolor='rgba(0, 0, 0, 0)',\n",
    "                      paper_bgcolor='rgba(0, 0, 0, 0)')\n",
    "    \n",
    "    #bandas de percentiles \n",
    "    p_ = all_preds.loc[all_preds['unique_id'] == ticker]\n",
    "    fig.add_trace(go.Scatter(x=p_['ds'], y=p_['p10'], mode='lines', line=dict(color='rgba(255, 165, 0, 0.2)'), name='p10'))\n",
    "    fig.add_trace(go.Scatter(x=p_['ds'], y=p_['p90'], mode='lines', line=dict(color='rgba(255, 165, 0, 0.2)'), name='p90', fill='tonexty', fillcolor='rgba(255, 165, 0, 0.2)'))\n",
    "    fig.add_trace(go.Scatter(x=p_['ds'], y=p_['p25'], mode='lines', line=dict(color='orange'), name='p25'))\n",
    "    fig.add_trace(go.Scatter(x=p_['ds'], y=p_['p75'], mode='lines', line=dict(color='orange'), name='p75', fill='tonexty', fillcolor='rgba(255, 165, 0, 0.2)'))\n",
    "    fig.add_trace(go.Scatter(x=p_['ds'], y=p_['pred'], mode='lines', line=dict(color='orange'), name='Forecast'))\n",
    "    return fig\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run_server(debug=True, port=8080, mode='inline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Guardamos las métricas para cada una de las series__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'comparison_tbl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Bravo15\\Desktop\\raico\\Proyecto final\\Project_Raiconet_101\\2.2 Modelos NN.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Bravo15/Desktop/raico/Proyecto%20final/Project_Raiconet_101/2.2%20Modelos%20NN.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m comparison_tbl\u001b[39m=\u001b[39mguardar_metricas(comparison_tbl, all_preds, exetime, \u001b[39m'\u001b[39m\u001b[39mGlounts Deep AR\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'comparison_tbl' is not defined"
     ]
    }
   ],
   "source": [
    "comparison_tbl=guardar_metricas(comparison_tbl, all_preds, exetime, 'Glounts Deep AR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serie</th>\n",
       "      <th>Modelo</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>sMAPE</th>\n",
       "      <th>Processing Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>impo_3</td>\n",
       "      <td>Glounts Deep AR</td>\n",
       "      <td>27.063334</td>\n",
       "      <td>32.217003</td>\n",
       "      <td>1.075632</td>\n",
       "      <td>50.5338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Impo 3</td>\n",
       "      <td>SARIMAX ([1, 2], 0, [5])</td>\n",
       "      <td>42.912352</td>\n",
       "      <td>77.237038</td>\n",
       "      <td>1.431710</td>\n",
       "      <td>2.6416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>expo_4</td>\n",
       "      <td>Glounts Deep AR</td>\n",
       "      <td>44.653334</td>\n",
       "      <td>66.411531</td>\n",
       "      <td>0.559923</td>\n",
       "      <td>50.5338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>expo_5</td>\n",
       "      <td>Glounts Deep AR</td>\n",
       "      <td>51.861113</td>\n",
       "      <td>58.219287</td>\n",
       "      <td>0.282507</td>\n",
       "      <td>50.5338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>impo_4</td>\n",
       "      <td>Glounts Deep AR</td>\n",
       "      <td>65.242221</td>\n",
       "      <td>72.757716</td>\n",
       "      <td>0.789762</td>\n",
       "      <td>50.5338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Expo 4</td>\n",
       "      <td>SARIMAX ([1, 2], 1, [2])</td>\n",
       "      <td>96.732396</td>\n",
       "      <td>137.010334</td>\n",
       "      <td>0.726832</td>\n",
       "      <td>1.6148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Impo 7</td>\n",
       "      <td>SARIMAX ([1, 2], 0, [10])</td>\n",
       "      <td>141.687432</td>\n",
       "      <td>183.721246</td>\n",
       "      <td>0.342107</td>\n",
       "      <td>8.5445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Impo 4</td>\n",
       "      <td>SARIMAX ([2], 0, [1])</td>\n",
       "      <td>185.779630</td>\n",
       "      <td>213.952750</td>\n",
       "      <td>0.812257</td>\n",
       "      <td>0.9748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Expo 3</td>\n",
       "      <td>SARIMAX ([3], 0, [1])</td>\n",
       "      <td>199.795894</td>\n",
       "      <td>367.519378</td>\n",
       "      <td>0.367942</td>\n",
       "      <td>3.9468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>impo_7</td>\n",
       "      <td>Glounts Deep AR</td>\n",
       "      <td>221.135552</td>\n",
       "      <td>239.400618</td>\n",
       "      <td>0.558031</td>\n",
       "      <td>50.5338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>impo_6</td>\n",
       "      <td>Glounts Deep AR</td>\n",
       "      <td>278.031114</td>\n",
       "      <td>324.557002</td>\n",
       "      <td>0.356682</td>\n",
       "      <td>50.5338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>impo_2</td>\n",
       "      <td>Glounts Deep AR</td>\n",
       "      <td>296.294440</td>\n",
       "      <td>324.679483</td>\n",
       "      <td>0.574232</td>\n",
       "      <td>50.5338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Impo 6</td>\n",
       "      <td>SARIMAX ([1], 0, [1])</td>\n",
       "      <td>357.309763</td>\n",
       "      <td>428.351523</td>\n",
       "      <td>0.482983</td>\n",
       "      <td>0.4468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>expo_3</td>\n",
       "      <td>Glounts Deep AR</td>\n",
       "      <td>368.453992</td>\n",
       "      <td>381.177427</td>\n",
       "      <td>0.812932</td>\n",
       "      <td>50.5338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Impo 5</td>\n",
       "      <td>SARIMAX ([2], 0, [2])</td>\n",
       "      <td>413.946660</td>\n",
       "      <td>609.900753</td>\n",
       "      <td>0.859657</td>\n",
       "      <td>2.2723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>impo_5</td>\n",
       "      <td>Glounts Deep AR</td>\n",
       "      <td>556.344442</td>\n",
       "      <td>804.479460</td>\n",
       "      <td>0.522969</td>\n",
       "      <td>50.5338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Expo 2</td>\n",
       "      <td>SARIMAX ([2], 0, [1])</td>\n",
       "      <td>651.448471</td>\n",
       "      <td>939.710109</td>\n",
       "      <td>1.340620</td>\n",
       "      <td>3.8069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Impo 2</td>\n",
       "      <td>SARIMAX ([1, 2], 0, [3, 4, 5])</td>\n",
       "      <td>814.903721</td>\n",
       "      <td>916.453730</td>\n",
       "      <td>0.728610</td>\n",
       "      <td>3.0545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>expo_1</td>\n",
       "      <td>Glounts Deep AR</td>\n",
       "      <td>843.685547</td>\n",
       "      <td>934.375832</td>\n",
       "      <td>0.705723</td>\n",
       "      <td>50.5338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>expo_2</td>\n",
       "      <td>Glounts Deep AR</td>\n",
       "      <td>856.187778</td>\n",
       "      <td>989.932385</td>\n",
       "      <td>1.399425</td>\n",
       "      <td>50.5338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>impo_1</td>\n",
       "      <td>Glounts Deep AR</td>\n",
       "      <td>935.277778</td>\n",
       "      <td>1041.540494</td>\n",
       "      <td>0.303231</td>\n",
       "      <td>50.5338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Impo 1</td>\n",
       "      <td>SARIMAX ([1, 2, 4, 5, 6], 0, [1, 2, 3])</td>\n",
       "      <td>1020.640873</td>\n",
       "      <td>1275.666636</td>\n",
       "      <td>0.290936</td>\n",
       "      <td>3.6511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Expo 1</td>\n",
       "      <td>SARIMAX ([2], 0, [1])</td>\n",
       "      <td>1081.461875</td>\n",
       "      <td>1263.594024</td>\n",
       "      <td>0.612268</td>\n",
       "      <td>3.6255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Serie                                   Modelo          MAE         RMSE  \\\n",
       "18  impo_3                          Glounts Deep AR    27.063334    32.217003   \n",
       "2   Impo 3                 SARIMAX ([1, 2], 0, [5])    42.912352    77.237038   \n",
       "14  expo_4                          Glounts Deep AR    44.653334    66.411531   \n",
       "15  expo_5                          Glounts Deep AR    51.861113    58.219287   \n",
       "19  impo_4                          Glounts Deep AR    65.242221    72.757716   \n",
       "10  Expo 4                 SARIMAX ([1, 2], 1, [2])    96.732396   137.010334   \n",
       "6   Impo 7                SARIMAX ([1, 2], 0, [10])   141.687432   183.721246   \n",
       "3   Impo 4                    SARIMAX ([2], 0, [1])   185.779630   213.952750   \n",
       "9   Expo 3                    SARIMAX ([3], 0, [1])   199.795894   367.519378   \n",
       "22  impo_7                          Glounts Deep AR   221.135552   239.400618   \n",
       "21  impo_6                          Glounts Deep AR   278.031114   324.557002   \n",
       "17  impo_2                          Glounts Deep AR   296.294440   324.679483   \n",
       "5   Impo 6                    SARIMAX ([1], 0, [1])   357.309763   428.351523   \n",
       "13  expo_3                          Glounts Deep AR   368.453992   381.177427   \n",
       "4   Impo 5                    SARIMAX ([2], 0, [2])   413.946660   609.900753   \n",
       "20  impo_5                          Glounts Deep AR   556.344442   804.479460   \n",
       "8   Expo 2                    SARIMAX ([2], 0, [1])   651.448471   939.710109   \n",
       "1   Impo 2           SARIMAX ([1, 2], 0, [3, 4, 5])   814.903721   916.453730   \n",
       "11  expo_1                          Glounts Deep AR   843.685547   934.375832   \n",
       "12  expo_2                          Glounts Deep AR   856.187778   989.932385   \n",
       "16  impo_1                          Glounts Deep AR   935.277778  1041.540494   \n",
       "0   Impo 1  SARIMAX ([1, 2, 4, 5, 6], 0, [1, 2, 3])  1020.640873  1275.666636   \n",
       "7   Expo 1                    SARIMAX ([2], 0, [1])  1081.461875  1263.594024   \n",
       "\n",
       "       sMAPE Processing Time  \n",
       "18  1.075632         50.5338  \n",
       "2   1.431710          2.6416  \n",
       "14  0.559923         50.5338  \n",
       "15  0.282507         50.5338  \n",
       "19  0.789762         50.5338  \n",
       "10  0.726832          1.6148  \n",
       "6   0.342107          8.5445  \n",
       "3   0.812257          0.9748  \n",
       "9   0.367942          3.9468  \n",
       "22  0.558031         50.5338  \n",
       "21  0.356682         50.5338  \n",
       "17  0.574232         50.5338  \n",
       "5   0.482983          0.4468  \n",
       "13  0.812932         50.5338  \n",
       "4   0.859657          2.2723  \n",
       "20  0.522969         50.5338  \n",
       "8   1.340620          3.8069  \n",
       "1   0.728610          3.0545  \n",
       "11  0.705723         50.5338  \n",
       "12  1.399425         50.5338  \n",
       "16  0.303231         50.5338  \n",
       "0   0.290936          3.6511  \n",
       "7   0.612268          3.6255  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models = comparison_tbl.groupby('Serie').apply(lambda group: group[group['MAE'] == group['MAE'].min()])\n",
    "best_models.drop(columns='Serie', inplace=True)\n",
    "best_models = best_models.groupby('Serie').first().reset_index()\n",
    "best_models.tail(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Glounts Deep AR - Variable exógena"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cotizacion dolar oficial\n",
    "\n",
    "Obtenida de: https://es.investing.com/currencies/usd-ars-historical-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cot_dolar_blue= pd.read_csv('Data/Datos históricos USD_ARSB.csv')\n",
    "df_cot_dolar_blue['Fecha'] = pd.to_datetime(df_cot_dolar_blue['Fecha'], format='%d.%m.%Y')\n",
    "df_cot_dolar_blue= df_cot_dolar_blue[['Fecha','Último']]\n",
    "df_cot_dolar_blue['Último']= df_cot_dolar_blue['Último'].str.replace(',', '.')\n",
    "df_cot_dolar_blue['Último']= df_cot_dolar_blue['Último'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Último</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>2019-02-03</td>\n",
       "      <td>37.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>2019-01-27</td>\n",
       "      <td>37.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>2019-01-20</td>\n",
       "      <td>38.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>2019-01-13</td>\n",
       "      <td>38.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>39.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Fecha  Último\n",
       "208 2019-02-03   37.38\n",
       "209 2019-01-27   37.62\n",
       "210 2019-01-20   38.12\n",
       "211 2019-01-13   38.88\n",
       "212 2019-01-06   39.00"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cot_dolar_blue.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df.merge(df_cot_dolar_blue, left_on='ds', right_on='Fecha', how='left')\n",
    "df_merged = df_merged.rename(columns={'Último': 'cotizacion'}).drop('Fecha', axis=1)\n",
    "df_merged['cotizacion']=df_merged['cotizacion'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>y</th>\n",
       "      <th>cotizacion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>impo_1</td>\n",
       "      <td>2813</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>impo_2</td>\n",
       "      <td>237</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>impo_3</td>\n",
       "      <td>50</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>impo_4</td>\n",
       "      <td>50</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>impo_5</td>\n",
       "      <td>1111</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>impo_6</td>\n",
       "      <td>890</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>impo_7</td>\n",
       "      <td>201</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>expo_1</td>\n",
       "      <td>1617</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>expo_2</td>\n",
       "      <td>281</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2120</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>expo_4</td>\n",
       "      <td>41</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>expo_5</td>\n",
       "      <td>191</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ds unique_id     y  cotizacion\n",
       "208  2023-01-01    impo_1  2813         352\n",
       "417  2023-01-01    impo_2   237         352\n",
       "626  2023-01-01    impo_3    50         352\n",
       "835  2023-01-01    impo_4    50         352\n",
       "1044 2023-01-01    impo_5  1111         352\n",
       "1080 2023-01-01    impo_6   890         352\n",
       "1289 2023-01-01    impo_7   201         352\n",
       "1498 2023-01-01    expo_1  1617         352\n",
       "1706 2023-01-01    expo_2   281         352\n",
       "2120 2023-01-01    expo_4    41         352\n",
       "2329 2023-01-01    expo_5   191         352"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[df_merged['ds']=='2023-01-01']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Definimos el set de train y test__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train= df_merged\n",
    "valid = df_merged[df_merged['ds'] >= '2022-11-01']\n",
    "\n",
    "#cuando agregamos una variable exogena la misma debe ser input en la fase de test, es decir debe ser una variable conocida a futuro.\n",
    "#Aunque en la practica es casi inviable conocer la cotizacion del dolar a futuro se podria crear un segundo modelo que prediga la misma, \n",
    "#pero en esta instancia a modo de prueba correre el modelo bajo el supuesto que podremos agregar la cotizacion del dolar futuro en el modelo \n",
    "#una vez que este en produccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = PandasDataset.from_long_dataframe(train,\n",
    "                                             target='y', \n",
    "                                             item_id='unique_id', \n",
    "                                             timestamp='ds',\n",
    "                                             freq='W', \n",
    "                                             feat_dynamic_real=['cotizacion']) #agregamos la variable exogena \n",
    "#future_lenght = 10 \n",
    "#pasarle al train todo el dataset, la variable target hasta el 1 de noviembre, y necesitos 10 valores de cot hacia el futuro \n",
    "#como es autoregresivo necesita los valores futuros, valor del dolar hasta hoy \n",
    "#prediga las dos variables -> deep VAR -> predecir las dos cosas, target + exogenas => estimar por fuera el dolar -> input nuevo modelo \n",
    "#hacer la prueba si realmente mejora evaluar las opciones => el valor observado futuro nunca lo voy a tener -> valor estimado != valor futuro \n",
    "#variable categorica estatica => pais de origen del motivo -> USA, EUROPA, CHINA etc -> static categorical no varia en el tiempo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Definicion del Modelo DeepAr - feat dynamic real__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bravo15\\anaconda3\\envs\\modelling-torch\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:108: PossibleUserWarning:\n",
      "\n",
      "You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "\n",
      "\n",
      "  | Name  | Type        | Params | In sizes | Out sizes  \n",
      "---------------------------------------------------------------\n",
      "0 | model | DeepARModel | 50.2 K | ?        | [1, 100, 9]\n",
      "---------------------------------------------------------------\n",
      "50.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "50.2 K    Total params\n",
      "0.201     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10a9582eed874cf59d13cea834d95f72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 12.67451 (best 12.67451), saving model to 'c:\\\\Users\\\\Bravo15\\\\Desktop\\\\raico\\\\Proyecto final\\\\Project_Raiconet_101\\\\lightning_logs\\\\version_131\\\\checkpoints\\\\epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' was not in top 1\n",
      "Epoch 2, global step 150: 'train_loss' was not in top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 12.49430 (best 12.49430), saving model to 'c:\\\\Users\\\\Bravo15\\\\Desktop\\\\raico\\\\Proyecto final\\\\Project_Raiconet_101\\\\lightning_logs\\\\version_131\\\\checkpoints\\\\epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' was not in top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 9.76146 (best 9.76146), saving model to 'c:\\\\Users\\\\Bravo15\\\\Desktop\\\\raico\\\\Proyecto final\\\\Project_Raiconet_101\\\\lightning_logs\\\\version_131\\\\checkpoints\\\\epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' was not in top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 9.68130 (best 9.68130), saving model to 'c:\\\\Users\\\\Bravo15\\\\Desktop\\\\raico\\\\Proyecto final\\\\Project_Raiconet_101\\\\lightning_logs\\\\version_131\\\\checkpoints\\\\epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' was not in top 1\n",
      "Epoch 9, global step 500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "tic = time.clock()\n",
    "estimator2 = DeepAREstimator(freq='W', #la frecuencia de los datos es semanal por lo que el modelo debe ser semanal tambien\n",
    "                            context_length=9, # el modelo va a usar las ultimas 9 semanas para predecir la siguientes 10\n",
    "                            prediction_length=9, # va a predecir las proximas 9 semanas \n",
    "                            num_layers=4, #el modelo posee 4 capas con un default de 40 nodos por capa \n",
    "                            dropout_rate= 0.2, #seteo de 20% de las units en una layer en cero de forma random, el default es 0.1\n",
    "                            trainer_kwargs={ 'max_epochs':10},#120, #en vez de poner un early stopping defino un max epoch de 30 ((210)\n",
    "                            num_feat_dynamic_real= int(1), \n",
    "                            distr_output= NegativeBinomialOutput())  #el default es Distribucion t-student, pero al usar negative binomial permite que las predicciones no tomen valores negativos\n",
    "\n",
    "predictor2 = estimator2.train(train_ds, num_workers=2)\n",
    "\n",
    "toc =  time.clock() #frenamos el cronometro y a continuacion creamos la variable que guarda el tiempo transcurrido desde que empezo a correr el modelo hasta q termino\n",
    "exetime = '{0:.4f}'.format(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_it, ts_it = make_evaluation_predictions(\n",
    "    dataset=train_ds,  \n",
    "    predictor=predictor2, \n",
    ")\n",
    "\n",
    "tss = list(ts_it)\n",
    "forecasts = list(forecast_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bravo15\\AppData\\Local\\Temp\\ipykernel_18072\\197479032.py:19: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7393604936422814"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds2 = list()\n",
    "for item in forecasts:\n",
    "    unique_id = item.item_id\n",
    "    p = item.samples.mean(axis=0)\n",
    "    p10 = np.percentile(item.samples, 10, axis=0)\n",
    "    p90 = np.percentile(item.samples, 90, axis=0)\n",
    "    p25 = np.percentile(item.samples, 25, axis=0)\n",
    "    p75 = np.percentile(item.samples, 75, axis=0)\n",
    "    dates = pd.date_range(start=item.start_date.to_timestamp(), periods=len(p), freq='W')\n",
    "    family_pred = pd.DataFrame({'ds': dates, \n",
    "                                'unique_id': unique_id,\n",
    "                                'pred': p,\n",
    "                                'p25': p25,\n",
    "                                'p75': p75,\n",
    "                                'p10': p10, \n",
    "                                'p90': p90})\n",
    "    all_preds2 += [family_pred]\n",
    "all_preds2 = pd.concat(all_preds2, ignore_index=True)\n",
    "valid.drop(columns='ds', inplace=True)\n",
    "all_preds2 = all_preds2.merge(valid, on=['ds', 'unique_id'], how='left')\n",
    "\n",
    "all_preds2.dropna(inplace=True)\n",
    "\n",
    "Metrics(all_preds2['y'], all_preds2['pred']).wmape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Resultados Obtenidos: Deep AR - feat dynamic real__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x290beff70a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "app2 = Dash(external_stylesheets=[dbc.themes.SLATE])\n",
    "\n",
    "\n",
    "dropdown = dcc.Dropdown(\n",
    "    id=\"ticker\",\n",
    "    options=[{\"label\": unique_id, \"value\": unique_id} for unique_id in df[\"unique_id\"].unique()],\n",
    "    value=\"impo_1\",\n",
    "    clearable=False, \n",
    "    style={'background-color': 'grey'}\n",
    ")\n",
    "\n",
    "app2.layout = html.Div([\n",
    "    html.H4('Deep AR - Feat dynamic real Resultados'),\n",
    "    html.P(\"Seleccionar motivo:\"),\n",
    "    dropdown,\n",
    "    dcc.Graph(id=\"time-series-chart\"),\n",
    "])\n",
    "\n",
    "\n",
    "@app2.callback(\n",
    "    Output(\"time-series-chart\", \"figure\"), \n",
    "    Input(\"ticker\", \"value\"))\n",
    "\n",
    "def display_time_series(ticker):\n",
    "    df_pivot = df.pivot(index='ds', columns='unique_id', values='y')\n",
    "    df_pivot = df_pivot.reset_index()\n",
    "    df_pivot = df_pivot.fillna(0)\n",
    "    \n",
    "    fig = px.line(df_pivot, x='ds', y=ticker, title=ticker, template='plotly_dark')\n",
    "    fig.update_layout(plot_bgcolor='rgba(0, 0, 0, 0)',\n",
    "                      paper_bgcolor='rgba(0, 0, 0, 0)')\n",
    "    \n",
    "    #bandas de percentiles \n",
    "    p_ = all_preds2.loc[all_preds2['unique_id'] == ticker]\n",
    "    fig.add_trace(go.Scatter(x=p_['ds'], y=p_['p10'], mode='lines', line=dict(color='rgba(255, 165, 0, 0.2)'), name='p10'))\n",
    "    fig.add_trace(go.Scatter(x=p_['ds'], y=p_['p90'], mode='lines', line=dict(color='rgba(255, 165, 0, 0.2)'), name='p90', fill='tonexty', fillcolor='rgba(255, 165, 0, 0.2)'))\n",
    "    fig.add_trace(go.Scatter(x=p_['ds'], y=p_['p25'], mode='lines', line=dict(color='orange'), name='p25'))\n",
    "    fig.add_trace(go.Scatter(x=p_['ds'], y=p_['p75'], mode='lines', line=dict(color='orange'), name='p75', fill='tonexty', fillcolor='rgba(255, 165, 0, 0.2)'))\n",
    "    fig.add_trace(go.Scatter(x=p_['ds'], y=p_['pred'], mode='lines', line=dict(color='orange'), name='Forecast'))\n",
    "    return fig\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app2.run_server(debug=True, port=8081, mode='inline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Guardamos las métricas para cada una de las series__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'comparison_tbl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Bravo15\\Desktop\\raico\\Proyecto final\\Project_Raiconet_101\\2.2 Modelos NN.ipynb Cell 35\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Bravo15/Desktop/raico/Proyecto%20final/Project_Raiconet_101/2.2%20Modelos%20NN.ipynb#X50sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m comparison_tbl\u001b[39m=\u001b[39mguardar_metricas(comparison_tbl, all_preds, exetime, \u001b[39m'\u001b[39m\u001b[39mGlounts Deep AR feat dynamic variable\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'comparison_tbl' is not defined"
     ]
    }
   ],
   "source": [
    "comparison_tbl=guardar_metricas(comparison_tbl, all_preds, exetime, 'Glounts Deep AR feat dynamic variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serie</th>\n",
       "      <th>Modelo</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>sMAPE</th>\n",
       "      <th>Processing Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>expo_1</td>\n",
       "      <td>Glounts Deep AR</td>\n",
       "      <td>736.127767</td>\n",
       "      <td>826.523713</td>\n",
       "      <td>0.649992</td>\n",
       "      <td>831.7742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>expo_2</td>\n",
       "      <td>Glounts Deep AR</td>\n",
       "      <td>782.855559</td>\n",
       "      <td>1038.220522</td>\n",
       "      <td>1.518301</td>\n",
       "      <td>831.7742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>expo_3</td>\n",
       "      <td>Glounts Deep AR</td>\n",
       "      <td>203.240002</td>\n",
       "      <td>215.670565</td>\n",
       "      <td>0.559893</td>\n",
       "      <td>831.7742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>expo_4</td>\n",
       "      <td>Glounts Deep AR</td>\n",
       "      <td>51.296667</td>\n",
       "      <td>71.753629</td>\n",
       "      <td>0.655892</td>\n",
       "      <td>831.7742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>expo_5</td>\n",
       "      <td>Glounts Deep AR</td>\n",
       "      <td>37.885553</td>\n",
       "      <td>52.572408</td>\n",
       "      <td>0.213746</td>\n",
       "      <td>831.7742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>impo_1</td>\n",
       "      <td>Glounts Deep AR</td>\n",
       "      <td>926.861084</td>\n",
       "      <td>1054.689090</td>\n",
       "      <td>0.302871</td>\n",
       "      <td>831.7742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>impo_2</td>\n",
       "      <td>Glounts Deep AR</td>\n",
       "      <td>104.382222</td>\n",
       "      <td>110.197790</td>\n",
       "      <td>0.261960</td>\n",
       "      <td>831.7742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>impo_3</td>\n",
       "      <td>Glounts Deep AR</td>\n",
       "      <td>25.522222</td>\n",
       "      <td>29.375341</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>831.7742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>impo_4</td>\n",
       "      <td>Glounts Deep AR</td>\n",
       "      <td>20.353333</td>\n",
       "      <td>25.710064</td>\n",
       "      <td>0.469926</td>\n",
       "      <td>831.7742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>impo_5</td>\n",
       "      <td>Glounts Deep AR</td>\n",
       "      <td>533.032227</td>\n",
       "      <td>799.136363</td>\n",
       "      <td>0.512526</td>\n",
       "      <td>831.7742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>impo_6</td>\n",
       "      <td>Glounts Deep AR</td>\n",
       "      <td>362.414452</td>\n",
       "      <td>464.085551</td>\n",
       "      <td>0.493684</td>\n",
       "      <td>831.7742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>impo_7</td>\n",
       "      <td>Glounts Deep AR</td>\n",
       "      <td>103.722219</td>\n",
       "      <td>123.266592</td>\n",
       "      <td>0.321367</td>\n",
       "      <td>831.7742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Serie           Modelo         MAE         RMSE     sMAPE Processing Time\n",
       "11  expo_1  Glounts Deep AR  736.127767   826.523713  0.649992        831.7742\n",
       "12  expo_2  Glounts Deep AR  782.855559  1038.220522  1.518301        831.7742\n",
       "13  expo_3  Glounts Deep AR  203.240002   215.670565  0.559893        831.7742\n",
       "14  expo_4  Glounts Deep AR   51.296667    71.753629  0.655892        831.7742\n",
       "15  expo_5  Glounts Deep AR   37.885553    52.572408  0.213746        831.7742\n",
       "16  impo_1  Glounts Deep AR  926.861084  1054.689090  0.302871        831.7742\n",
       "17  impo_2  Glounts Deep AR  104.382222   110.197790  0.261960        831.7742\n",
       "18  impo_3  Glounts Deep AR   25.522222    29.375341  0.965812        831.7742\n",
       "19  impo_4  Glounts Deep AR   20.353333    25.710064  0.469926        831.7742\n",
       "20  impo_5  Glounts Deep AR  533.032227   799.136363  0.512526        831.7742\n",
       "21  impo_6  Glounts Deep AR  362.414452   464.085551  0.493684        831.7742\n",
       "22  impo_7  Glounts Deep AR  103.722219   123.266592  0.321367        831.7742"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models = comparison_tbl.groupby('Serie').apply(lambda group: group[group['RMSE'] == group['RMSE'].min()])\n",
    "best_models.drop(columns='Serie', inplace=True)\n",
    "best_models = best_models.groupby('Serie').first().reset_index()\n",
    "best_models.tail(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**  A pesar de agregar la variable exogena del tipo de cambio, aunque los resultados del modelo no mejoran y aun el modelo Glounts Deep AR permite obtener mejores predicciones. Comparando los resultados entre el primer modelo Deep Ar y el segundo Deep Ar con feat dynamic real, se observa que ambos no logran captar las tendencias y cambios drasticos existentes en los datos. Si bien los resultados son los mejores obtenidos hasta el momento comparando con los modelos clasicos y de ML, aun asi el modelo permite obtener predicciones con cierto margen de error pero aun no logra captar los cambios abruptos que poseen las series. En gran medida se debe a la naturaleza del modelo Deep AR, ya que como su nombre indica al ser un modelo autoregresivo busca patrones en valores historicos de la serie buscando hacer inferencias con distribuciones conocidas. Pero aun asi, como los datos presentes son erraticos y no revelan una distribucion aparente este tipo de modelo no parece ser suficiente. A continuacion, presentare otro tipo de modelo de redes neuronales el cual se basa en en redes neuronales recurrentes y long short term memory, de esta forma logra captar estos \"changing points\" o cambios erraticos que presentan este tipo de series. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modelling-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
