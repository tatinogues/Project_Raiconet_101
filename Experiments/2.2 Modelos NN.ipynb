{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 101\n",
    "### PARTE 2.3 - Modelos Redes Neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contenido\n",
    "- [Modelado](#modelos)\n",
    "\n",
    "    - [**2.3.1 Glounts Deep Ar**](#1)\n",
    "        - [Definicion del modelo](#def)\n",
    "        - [Modelado con variable exogena](#exo)\n",
    "        - [Comparacion de Resultados](#1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import funciones_utiles\n",
    "from funciones_utiles import DataPrep, Metrics, guardar_metricas\n",
    "\n",
    "import time\n",
    "time.clock = time.time\n",
    "\n",
    "from gluonts.dataset.pandas import PandasDataset\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.torch.model.deepar import DeepAREstimator\n",
    "from gluonts.torch.distributions import NegativeBinomialOutput\n",
    "from gluonts.evaluation import make_evaluation_predictions\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from dash import Dash, dcc, html, Input, Output\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import dash_bootstrap_components as dbc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Importamos los df__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_tbl= pd.read_csv('Data/Modelado/comparison_tbl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>impo_1</td>\n",
       "      <td>1950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-13</td>\n",
       "      <td>impo_1</td>\n",
       "      <td>2402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-20</td>\n",
       "      <td>impo_1</td>\n",
       "      <td>2782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-27</td>\n",
       "      <td>impo_1</td>\n",
       "      <td>3263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-02-03</td>\n",
       "      <td>impo_1</td>\n",
       "      <td>3843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ds unique_id     y\n",
       "0 2019-01-06    impo_1  1950\n",
       "1 2019-01-13    impo_1  2402\n",
       "2 2019-01-20    impo_1  2782\n",
       "3 2019-01-27    impo_1  3263\n",
       "4 2019-02-03    impo_1  3843"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= DataPrep().unificar_df()\n",
    "df['y']=df['y'].astype(int)\n",
    "df['ds']= pd.to_datetime(df['ds'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ds', 'unique_id', 'y'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Glounts Deep Ar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Definimos el set de train y test__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.loc[df['ds'] < '2022-11-01']\n",
    "valid = df.loc[df['ds'] >= '2022-11-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = PandasDataset.from_long_dataframe(train,\n",
    "                                             target='y',\n",
    "                                             item_id='unique_id', \n",
    "                                             timestamp='ds',\n",
    "                                             freq='W')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Definicion del modelo DeepAr__\n",
    "\n",
    "La distribucion por default de DeepAR es un distribucion t-student, pero para modelar los datos es preferible que sea una Negative Binomial ya que permite obtener valores pertenecientes a los Reales Positivos, y no predicciones negativas como ocurre con la distribucion por deafault. Esta informacion es conocidad gracias al domain knowledge que no es posible que hayan valores de kilos negativos sino que pueden tomar valores 0 o positivos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\Bravo15\\anaconda3\\envs\\modelling-torch\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:108: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\n",
      "\n",
      "  | Name  | Type        | Params | In sizes | Out sizes   \n",
      "----------------------------------------------------------------\n",
      "0 | model | DeepARModel | 50.0 K | ?        | [1, 100, 10]\n",
      "----------------------------------------------------------------\n",
      "50.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "50.0 K    Total params\n",
      "0.200     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "065aa5d897ec49a88216a58c338a1745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 12.99315 (best 12.99315), saving model to 'c:\\\\Users\\\\Bravo15\\\\Desktop\\\\raico\\\\Proyecto final\\\\Project_Raiconet_101\\\\Experiments\\\\lightning_logs\\\\version_8\\\\checkpoints\\\\epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' was not in top 1\n",
      "Epoch 2, global step 150: 'train_loss' was not in top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 9.02138 (best 9.02138), saving model to 'c:\\\\Users\\\\Bravo15\\\\Desktop\\\\raico\\\\Proyecto final\\\\Project_Raiconet_101\\\\Experiments\\\\lightning_logs\\\\version_8\\\\checkpoints\\\\epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' was not in top 1\n",
      "Epoch 5, global step 300: 'train_loss' was not in top 1\n",
      "Epoch 6, global step 350: 'train_loss' was not in top 1\n",
      "Epoch 7, global step 400: 'train_loss' was not in top 1\n",
      "Epoch 8, global step 450: 'train_loss' was not in top 1\n",
      "Epoch 9, global step 500: 'train_loss' was not in top 1\n",
      "Epoch 10, global step 550: 'train_loss' was not in top 1\n",
      "Epoch 11, global step 600: 'train_loss' was not in top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 7.78856 (best 7.78856), saving model to 'c:\\\\Users\\\\Bravo15\\\\Desktop\\\\raico\\\\Proyecto final\\\\Project_Raiconet_101\\\\Experiments\\\\lightning_logs\\\\version_8\\\\checkpoints\\\\epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' was not in top 1\n",
      "Epoch 14, global step 750: 'train_loss' was not in top 1\n",
      "Epoch 15, global step 800: 'train_loss' was not in top 1\n",
      "Epoch 16, global step 850: 'train_loss' was not in top 1\n",
      "Epoch 17, global step 900: 'train_loss' was not in top 1\n",
      "Epoch 18, global step 950: 'train_loss' was not in top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 7.73659 (best 7.73659), saving model to 'c:\\\\Users\\\\Bravo15\\\\Desktop\\\\raico\\\\Proyecto final\\\\Project_Raiconet_101\\\\Experiments\\\\lightning_logs\\\\version_8\\\\checkpoints\\\\epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 6.33789 (best 6.33789), saving model to 'c:\\\\Users\\\\Bravo15\\\\Desktop\\\\raico\\\\Proyecto final\\\\Project_Raiconet_101\\\\Experiments\\\\lightning_logs\\\\version_8\\\\checkpoints\\\\epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached 6.28197 (best 6.28197), saving model to 'c:\\\\Users\\\\Bravo15\\\\Desktop\\\\raico\\\\Proyecto final\\\\Project_Raiconet_101\\\\Experiments\\\\lightning_logs\\\\version_8\\\\checkpoints\\\\epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
      "Epoch 33, global step 1700: 'train_loss' reached 6.21800 (best 6.21800), saving model to 'c:\\\\Users\\\\Bravo15\\\\Desktop\\\\raico\\\\Proyecto final\\\\Project_Raiconet_101\\\\Experiments\\\\lightning_logs\\\\version_8\\\\checkpoints\\\\epoch=33-step=1700.ckpt' as top 1\n",
      "Epoch 34, global step 1750: 'train_loss' was not in top 1\n",
      "Epoch 35, global step 1800: 'train_loss' was not in top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' reached 6.21193 (best 6.21193), saving model to 'c:\\\\Users\\\\Bravo15\\\\Desktop\\\\raico\\\\Proyecto final\\\\Project_Raiconet_101\\\\Experiments\\\\lightning_logs\\\\version_8\\\\checkpoints\\\\epoch=37-step=1900.ckpt' as top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' was not in top 1\n",
      "Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
      "Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached 6.19062 (best 6.19062), saving model to 'c:\\\\Users\\\\Bravo15\\\\Desktop\\\\raico\\\\Proyecto final\\\\Project_Raiconet_101\\\\Experiments\\\\lightning_logs\\\\version_8\\\\checkpoints\\\\epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
      "Epoch 47, global step 2400: 'train_loss' reached 6.18228 (best 6.18228), saving model to 'c:\\\\Users\\\\Bravo15\\\\Desktop\\\\raico\\\\Proyecto final\\\\Project_Raiconet_101\\\\Experiments\\\\lightning_logs\\\\version_8\\\\checkpoints\\\\epoch=47-step=2400.ckpt' as top 1\n",
      "Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
      "Epoch 49, global step 2500: 'train_loss' reached 6.13069 (best 6.13069), saving model to 'c:\\\\Users\\\\Bravo15\\\\Desktop\\\\raico\\\\Proyecto final\\\\Project_Raiconet_101\\\\Experiments\\\\lightning_logs\\\\version_8\\\\checkpoints\\\\epoch=49-step=2500.ckpt' as top 1\n",
      "Epoch 50, global step 2550: 'train_loss' reached 6.11035 (best 6.11035), saving model to 'c:\\\\Users\\\\Bravo15\\\\Desktop\\\\raico\\\\Proyecto final\\\\Project_Raiconet_101\\\\Experiments\\\\lightning_logs\\\\version_8\\\\checkpoints\\\\epoch=50-step=2550.ckpt' as top 1\n",
      "Epoch 51, global step 2600: 'train_loss' was not in top 1\n",
      "Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
      "Epoch 53, global step 2700: 'train_loss' was not in top 1\n",
      "Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
      "Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
      "Epoch 56, global step 2850: 'train_loss' was not in top 1\n",
      "Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
      "Epoch 58, global step 2950: 'train_loss' was not in top 1\n",
      "Epoch 59, global step 3000: 'train_loss' was not in top 1\n",
      "Epoch 60, global step 3050: 'train_loss' reached 6.07509 (best 6.07509), saving model to 'c:\\\\Users\\\\Bravo15\\\\Desktop\\\\raico\\\\Proyecto final\\\\Project_Raiconet_101\\\\Experiments\\\\lightning_logs\\\\version_8\\\\checkpoints\\\\epoch=60-step=3050.ckpt' as top 1\n",
      "Epoch 61, global step 3100: 'train_loss' was not in top 1\n",
      "Epoch 62, global step 3150: 'train_loss' was not in top 1\n",
      "Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
      "Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
      "Epoch 65, global step 3300: 'train_loss' was not in top 1\n",
      "Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
      "Epoch 67, global step 3400: 'train_loss' reached 6.07502 (best 6.07502), saving model to 'c:\\\\Users\\\\Bravo15\\\\Desktop\\\\raico\\\\Proyecto final\\\\Project_Raiconet_101\\\\Experiments\\\\lightning_logs\\\\version_8\\\\checkpoints\\\\epoch=67-step=3400.ckpt' as top 1\n",
      "Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
      "Epoch 69, global step 3500: 'train_loss' was not in top 1\n",
      "Epoch 70, global step 3550: 'train_loss' was not in top 1\n",
      "Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
      "Epoch 72, global step 3650: 'train_loss' was not in top 1\n",
      "Epoch 73, global step 3700: 'train_loss' reached 6.07404 (best 6.07404), saving model to 'c:\\\\Users\\\\Bravo15\\\\Desktop\\\\raico\\\\Proyecto final\\\\Project_Raiconet_101\\\\Experiments\\\\lightning_logs\\\\version_8\\\\checkpoints\\\\epoch=73-step=3700.ckpt' as top 1\n",
      "Epoch 74, global step 3750: 'train_loss' reached 6.04820 (best 6.04820), saving model to 'c:\\\\Users\\\\Bravo15\\\\Desktop\\\\raico\\\\Proyecto final\\\\Project_Raiconet_101\\\\Experiments\\\\lightning_logs\\\\version_8\\\\checkpoints\\\\epoch=74-step=3750.ckpt' as top 1\n",
      "Epoch 75, global step 3800: 'train_loss' reached 6.04473 (best 6.04473), saving model to 'c:\\\\Users\\\\Bravo15\\\\Desktop\\\\raico\\\\Proyecto final\\\\Project_Raiconet_101\\\\Experiments\\\\lightning_logs\\\\version_8\\\\checkpoints\\\\epoch=75-step=3800.ckpt' as top 1\n",
      "Epoch 76, global step 3850: 'train_loss' reached 6.04011 (best 6.04011), saving model to 'c:\\\\Users\\\\Bravo15\\\\Desktop\\\\raico\\\\Proyecto final\\\\Project_Raiconet_101\\\\Experiments\\\\lightning_logs\\\\version_8\\\\checkpoints\\\\epoch=76-step=3850.ckpt' as top 1\n",
      "Epoch 77, global step 3900: 'train_loss' was not in top 1\n",
      "Epoch 78, global step 3950: 'train_loss' was not in top 1\n",
      "Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
      "Epoch 80, global step 4050: 'train_loss' reached 5.99052 (best 5.99052), saving model to 'c:\\\\Users\\\\Bravo15\\\\Desktop\\\\raico\\\\Proyecto final\\\\Project_Raiconet_101\\\\Experiments\\\\lightning_logs\\\\version_8\\\\checkpoints\\\\epoch=80-step=4050.ckpt' as top 1\n",
      "Epoch 81, global step 4100: 'train_loss' was not in top 1\n",
      "Epoch 82, global step 4150: 'train_loss' was not in top 1\n",
      "Epoch 83, global step 4200: 'train_loss' reached 5.97785 (best 5.97785), saving model to 'c:\\\\Users\\\\Bravo15\\\\Desktop\\\\raico\\\\Proyecto final\\\\Project_Raiconet_101\\\\Experiments\\\\lightning_logs\\\\version_8\\\\checkpoints\\\\epoch=83-step=4200.ckpt' as top 1\n",
      "Epoch 84, global step 4250: 'train_loss' was not in top 1\n",
      "Epoch 85, global step 4300: 'train_loss' was not in top 1\n",
      "Epoch 86, global step 4350: 'train_loss' reached 5.92815 (best 5.92815), saving model to 'c:\\\\Users\\\\Bravo15\\\\Desktop\\\\raico\\\\Proyecto final\\\\Project_Raiconet_101\\\\Experiments\\\\lightning_logs\\\\version_8\\\\checkpoints\\\\epoch=86-step=4350.ckpt' as top 1\n",
      "Epoch 87, global step 4400: 'train_loss' was not in top 1\n",
      "Epoch 88, global step 4450: 'train_loss' was not in top 1\n",
      "Epoch 89, global step 4500: 'train_loss' was not in top 1\n",
      "Epoch 90, global step 4550: 'train_loss' was not in top 1\n",
      "Epoch 91, global step 4600: 'train_loss' was not in top 1\n",
      "Epoch 92, global step 4650: 'train_loss' was not in top 1\n",
      "Epoch 93, global step 4700: 'train_loss' was not in top 1\n",
      "Epoch 94, global step 4750: 'train_loss' was not in top 1\n",
      "Epoch 95, global step 4800: 'train_loss' was not in top 1\n",
      "Epoch 96, global step 4850: 'train_loss' was not in top 1\n",
      "Epoch 97, global step 4900: 'train_loss' was not in top 1\n",
      "Epoch 98, global step 4950: 'train_loss' was not in top 1\n",
      "Epoch 99, global step 5000: 'train_loss' was not in top 1\n",
      "Epoch 100, global step 5050: 'train_loss' was not in top 1\n",
      "Epoch 101, global step 5100: 'train_loss' was not in top 1\n",
      "Epoch 102, global step 5150: 'train_loss' was not in top 1\n",
      "Epoch 103, global step 5200: 'train_loss' was not in top 1\n",
      "Epoch 104, global step 5250: 'train_loss' was not in top 1\n",
      "Epoch 105, global step 5300: 'train_loss' was not in top 1\n",
      "Epoch 106, global step 5350: 'train_loss' was not in top 1\n",
      "Epoch 107, global step 5400: 'train_loss' was not in top 1\n",
      "Epoch 108, global step 5450: 'train_loss' was not in top 1\n",
      "Epoch 109, global step 5500: 'train_loss' was not in top 1\n",
      "Epoch 110, global step 5550: 'train_loss' was not in top 1\n",
      "Epoch 111, global step 5600: 'train_loss' was not in top 1\n",
      "Epoch 112, global step 5650: 'train_loss' was not in top 1\n",
      "Epoch 113, global step 5700: 'train_loss' was not in top 1\n",
      "Epoch 114, global step 5750: 'train_loss' was not in top 1\n",
      "Epoch 115, global step 5800: 'train_loss' was not in top 1\n",
      "Epoch 116, global step 5850: 'train_loss' was not in top 1\n",
      "Epoch 117, global step 5900: 'train_loss' was not in top 1\n",
      "Epoch 118, global step 5950: 'train_loss' was not in top 1\n",
      "Epoch 119, global step 6000: 'train_loss' was not in top 1\n",
      "Epoch 120, global step 6050: 'train_loss' was not in top 1\n",
      "Epoch 121, global step 6100: 'train_loss' was not in top 1\n",
      "Epoch 122, global step 6150: 'train_loss' was not in top 1\n",
      "Epoch 123, global step 6200: 'train_loss' was not in top 1\n",
      "Epoch 124, global step 6250: 'train_loss' was not in top 1\n",
      "Epoch 125, global step 6300: 'train_loss' was not in top 1\n",
      "Epoch 126, global step 6350: 'train_loss' was not in top 1\n",
      "Epoch 127, global step 6400: 'train_loss' was not in top 1\n",
      "Epoch 128, global step 6450: 'train_loss' was not in top 1\n",
      "Epoch 129, global step 6500: 'train_loss' was not in top 1\n",
      "Epoch 130, global step 6550: 'train_loss' was not in top 1\n",
      "Epoch 131, global step 6600: 'train_loss' was not in top 1\n",
      "Epoch 132, global step 6650: 'train_loss' was not in top 1\n",
      "Epoch 133, global step 6700: 'train_loss' reached 5.92227 (best 5.92227), saving model to 'c:\\\\Users\\\\Bravo15\\\\Desktop\\\\raico\\\\Proyecto final\\\\Project_Raiconet_101\\\\Experiments\\\\lightning_logs\\\\version_8\\\\checkpoints\\\\epoch=133-step=6700.ckpt' as top 1\n",
      "Epoch 134, global step 6750: 'train_loss' was not in top 1\n",
      "Epoch 135, global step 6800: 'train_loss' was not in top 1\n",
      "Epoch 136, global step 6850: 'train_loss' was not in top 1\n",
      "Epoch 137, global step 6900: 'train_loss' was not in top 1\n",
      "Epoch 138, global step 6950: 'train_loss' was not in top 1\n",
      "Epoch 139, global step 7000: 'train_loss' was not in top 1\n",
      "Epoch 140, global step 7050: 'train_loss' was not in top 1\n",
      "Epoch 141, global step 7100: 'train_loss' was not in top 1\n",
      "Epoch 142, global step 7150: 'train_loss' was not in top 1\n",
      "Epoch 143, global step 7200: 'train_loss' was not in top 1\n",
      "Epoch 144, global step 7250: 'train_loss' was not in top 1\n",
      "Epoch 145, global step 7300: 'train_loss' was not in top 1\n",
      "Epoch 146, global step 7350: 'train_loss' was not in top 1\n",
      "Epoch 147, global step 7400: 'train_loss' was not in top 1\n",
      "Epoch 148, global step 7450: 'train_loss' was not in top 1\n",
      "Epoch 149, global step 7500: 'train_loss' was not in top 1\n",
      "Epoch 150, global step 7550: 'train_loss' was not in top 1\n",
      "Epoch 151, global step 7600: 'train_loss' was not in top 1\n",
      "Epoch 152, global step 7650: 'train_loss' was not in top 1\n",
      "Epoch 153, global step 7700: 'train_loss' was not in top 1\n",
      "Epoch 154, global step 7750: 'train_loss' was not in top 1\n",
      "Epoch 155, global step 7800: 'train_loss' was not in top 1\n",
      "Epoch 156, global step 7850: 'train_loss' was not in top 1\n",
      "Epoch 157, global step 7900: 'train_loss' was not in top 1\n",
      "Epoch 158, global step 7950: 'train_loss' was not in top 1\n",
      "Epoch 159, global step 8000: 'train_loss' was not in top 1\n",
      "Epoch 160, global step 8050: 'train_loss' was not in top 1\n",
      "Epoch 161, global step 8100: 'train_loss' was not in top 1\n",
      "Epoch 162, global step 8150: 'train_loss' was not in top 1\n",
      "Epoch 163, global step 8200: 'train_loss' was not in top 1\n",
      "Epoch 164, global step 8250: 'train_loss' was not in top 1\n",
      "Epoch 165, global step 8300: 'train_loss' was not in top 1\n",
      "Epoch 166, global step 8350: 'train_loss' was not in top 1\n",
      "Epoch 167, global step 8400: 'train_loss' was not in top 1\n",
      "Epoch 168, global step 8450: 'train_loss' was not in top 1\n",
      "Epoch 169, global step 8500: 'train_loss' was not in top 1\n",
      "Epoch 170, global step 8550: 'train_loss' was not in top 1\n",
      "Epoch 171, global step 8600: 'train_loss' was not in top 1\n",
      "Epoch 172, global step 8650: 'train_loss' was not in top 1\n",
      "Epoch 173, global step 8700: 'train_loss' was not in top 1\n",
      "Epoch 174, global step 8750: 'train_loss' was not in top 1\n",
      "Epoch 175, global step 8800: 'train_loss' was not in top 1\n",
      "Epoch 176, global step 8850: 'train_loss' was not in top 1\n",
      "Epoch 177, global step 8900: 'train_loss' was not in top 1\n",
      "Epoch 178, global step 8950: 'train_loss' was not in top 1\n",
      "Epoch 179, global step 9000: 'train_loss' was not in top 1\n",
      "Epoch 180, global step 9050: 'train_loss' was not in top 1\n",
      "Epoch 181, global step 9100: 'train_loss' was not in top 1\n",
      "Epoch 182, global step 9150: 'train_loss' was not in top 1\n",
      "Epoch 183, global step 9200: 'train_loss' was not in top 1\n",
      "Epoch 184, global step 9250: 'train_loss' was not in top 1\n",
      "Epoch 185, global step 9300: 'train_loss' was not in top 1\n",
      "Epoch 186, global step 9350: 'train_loss' was not in top 1\n",
      "Epoch 187, global step 9400: 'train_loss' was not in top 1\n",
      "Epoch 188, global step 9450: 'train_loss' was not in top 1\n",
      "Epoch 189, global step 9500: 'train_loss' was not in top 1\n",
      "Epoch 190, global step 9550: 'train_loss' was not in top 1\n",
      "Epoch 191, global step 9600: 'train_loss' was not in top 1\n",
      "Epoch 192, global step 9650: 'train_loss' was not in top 1\n",
      "Epoch 193, global step 9700: 'train_loss' was not in top 1\n",
      "Epoch 194, global step 9750: 'train_loss' was not in top 1\n",
      "Epoch 195, global step 9800: 'train_loss' was not in top 1\n",
      "Epoch 196, global step 9850: 'train_loss' was not in top 1\n",
      "Epoch 197, global step 9900: 'train_loss' was not in top 1\n",
      "Epoch 198, global step 9950: 'train_loss' was not in top 1\n",
      "Epoch 199, global step 10000: 'train_loss' was not in top 1\n",
      "Epoch 200, global step 10050: 'train_loss' was not in top 1\n",
      "Epoch 201, global step 10100: 'train_loss' was not in top 1\n",
      "Epoch 202, global step 10150: 'train_loss' was not in top 1\n",
      "Epoch 203, global step 10200: 'train_loss' was not in top 1\n",
      "Epoch 204, global step 10250: 'train_loss' was not in top 1\n",
      "Epoch 205, global step 10300: 'train_loss' was not in top 1\n",
      "Epoch 206, global step 10350: 'train_loss' was not in top 1\n",
      "Epoch 207, global step 10400: 'train_loss' was not in top 1\n",
      "Epoch 208, global step 10450: 'train_loss' was not in top 1\n",
      "Epoch 209, global step 10500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=210` reached.\n"
     ]
    }
   ],
   "source": [
    "tic = time.clock()\n",
    "estimator = DeepAREstimator(freq='W', #la frecuencia de los datos es semanal por lo que el modelo debe ser semanal tambien\n",
    "                            context_length=10, # el modelo va a usar las ultimas 10 semanas para predecir las siguientes 10, window de 10\n",
    "                            prediction_length=10, # va a predecir las proximas 10 semanas \n",
    "                            num_layers=4, #el modelo posee 40 capas con un default de 40 nodos por capa \n",
    "                            dropout_rate= 0.2, #seteo de 20% de las units en una layer en cero de forma random\n",
    "                            trainer_kwargs={ 'max_epochs':210},#210 epochs\n",
    "                            distr_output= NegativeBinomialOutput()) #el default es Distribucion t-student, pero al usar negative binomial permite que las predicciones no tomen valores negativos\n",
    "                        \n",
    "predictor = estimator.train(train_ds, num_workers= 2)\n",
    "\n",
    "toc =  time.clock() #frenamos el cronometro y a continuacion creamos la variable que guarda el tiempo transcurrido desde que empezo a correr el modelo hasta q termino\n",
    "exetime = '{0:.4f}'.format(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74301018972703"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = list(predictor.predict(train_ds))\n",
    "\n",
    "all_preds = list()\n",
    "for item in pred:\n",
    "    unique_id = item.item_id\n",
    "    p = item.samples.mean(axis=0)\n",
    "    p10 = np.percentile(item.samples, 10, axis=0)\n",
    "    p90 = np.percentile(item.samples, 90, axis=0)\n",
    "    p25 = np.percentile(item.samples, 25, axis=0)\n",
    "    p75 = np.percentile(item.samples, 75, axis=0)\n",
    "    dates = pd.date_range(start=item.start_date.to_timestamp(), periods=len(p), freq='W')\n",
    "    family_pred = pd.DataFrame({'ds': dates, \n",
    "                                'unique_id': unique_id,\n",
    "                                'pred': p,\n",
    "                                'p25': p25,\n",
    "                                'p75': p75,\n",
    "                                'p10': p10, \n",
    "                                'p90': p90})\n",
    "    all_preds += [family_pred]\n",
    "all_preds = pd.concat(all_preds, ignore_index=True)\n",
    "\n",
    "all_preds = all_preds.merge(valid, on=['ds', 'unique_id'], how='left')\n",
    "\n",
    "all_preds.dropna(inplace=True)\n",
    "\n",
    "Metrics(all_preds['y'], all_preds['pred']).calculate_smape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>pred</th>\n",
       "      <th>p25</th>\n",
       "      <th>p75</th>\n",
       "      <th>p10</th>\n",
       "      <th>p90</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-11-06</td>\n",
       "      <td>expo_1</td>\n",
       "      <td>1864.280029</td>\n",
       "      <td>1256.25</td>\n",
       "      <td>2380.75</td>\n",
       "      <td>1030.4</td>\n",
       "      <td>2843.9</td>\n",
       "      <td>2720.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-11-13</td>\n",
       "      <td>expo_1</td>\n",
       "      <td>2714.030029</td>\n",
       "      <td>1689.00</td>\n",
       "      <td>3547.25</td>\n",
       "      <td>1174.8</td>\n",
       "      <td>4901.0</td>\n",
       "      <td>290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-11-20</td>\n",
       "      <td>expo_1</td>\n",
       "      <td>2519.790039</td>\n",
       "      <td>1214.75</td>\n",
       "      <td>3603.00</td>\n",
       "      <td>733.4</td>\n",
       "      <td>4865.0</td>\n",
       "      <td>906.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-11-27</td>\n",
       "      <td>expo_1</td>\n",
       "      <td>2802.889893</td>\n",
       "      <td>1408.00</td>\n",
       "      <td>3376.50</td>\n",
       "      <td>844.4</td>\n",
       "      <td>4947.6</td>\n",
       "      <td>2408.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-04</td>\n",
       "      <td>expo_1</td>\n",
       "      <td>2901.620117</td>\n",
       "      <td>2005.50</td>\n",
       "      <td>3554.00</td>\n",
       "      <td>1455.2</td>\n",
       "      <td>4628.8</td>\n",
       "      <td>326.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2022-12-04</td>\n",
       "      <td>impo_7</td>\n",
       "      <td>253.550003</td>\n",
       "      <td>146.75</td>\n",
       "      <td>333.00</td>\n",
       "      <td>101.3</td>\n",
       "      <td>464.3</td>\n",
       "      <td>278.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2022-12-11</td>\n",
       "      <td>impo_7</td>\n",
       "      <td>232.279999</td>\n",
       "      <td>138.75</td>\n",
       "      <td>292.25</td>\n",
       "      <td>72.9</td>\n",
       "      <td>433.4</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2022-12-18</td>\n",
       "      <td>impo_7</td>\n",
       "      <td>248.809998</td>\n",
       "      <td>170.50</td>\n",
       "      <td>308.25</td>\n",
       "      <td>95.8</td>\n",
       "      <td>425.7</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2022-12-25</td>\n",
       "      <td>impo_7</td>\n",
       "      <td>203.410004</td>\n",
       "      <td>122.00</td>\n",
       "      <td>262.50</td>\n",
       "      <td>71.1</td>\n",
       "      <td>342.3</td>\n",
       "      <td>409.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>impo_7</td>\n",
       "      <td>172.229996</td>\n",
       "      <td>94.75</td>\n",
       "      <td>217.75</td>\n",
       "      <td>53.9</td>\n",
       "      <td>339.4</td>\n",
       "      <td>201.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ds unique_id         pred      p25      p75     p10     p90  \\\n",
       "0   2022-11-06    expo_1  1864.280029  1256.25  2380.75  1030.4  2843.9   \n",
       "1   2022-11-13    expo_1  2714.030029  1689.00  3547.25  1174.8  4901.0   \n",
       "2   2022-11-20    expo_1  2519.790039  1214.75  3603.00   733.4  4865.0   \n",
       "3   2022-11-27    expo_1  2802.889893  1408.00  3376.50   844.4  4947.6   \n",
       "4   2022-12-04    expo_1  2901.620117  2005.50  3554.00  1455.2  4628.8   \n",
       "..         ...       ...          ...      ...      ...     ...     ...   \n",
       "114 2022-12-04    impo_7   253.550003   146.75   333.00   101.3   464.3   \n",
       "115 2022-12-11    impo_7   232.279999   138.75   292.25    72.9   433.4   \n",
       "116 2022-12-18    impo_7   248.809998   170.50   308.25    95.8   425.7   \n",
       "117 2022-12-25    impo_7   203.410004   122.00   262.50    71.1   342.3   \n",
       "118 2023-01-01    impo_7   172.229996    94.75   217.75    53.9   339.4   \n",
       "\n",
       "          y  \n",
       "0    2720.0  \n",
       "1     290.0  \n",
       "2     906.0  \n",
       "3    2408.0  \n",
       "4     326.0  \n",
       "..      ...  \n",
       "114   278.0  \n",
       "115   182.0  \n",
       "116   260.0  \n",
       "117   409.0  \n",
       "118   201.0  \n",
       "\n",
       "[104 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Resultados Obtenidos: Deep AR__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8080/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1a989314dc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "app = Dash(external_stylesheets=[dbc.themes.SLATE])\n",
    "\n",
    "\n",
    "\n",
    "dropdown = dcc.Dropdown(\n",
    "    id=\"ticker\",\n",
    "    options=[{\"label\": unique_id, \"value\": unique_id} for unique_id in df[\"unique_id\"].unique()],\n",
    "    value=\"impo_1\",\n",
    "    clearable=False, \n",
    "    style={'background-color': 'grey'}\n",
    ")\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H4('Deep AR Resultados'),\n",
    "    html.P(\"Seleccionar motivo:\"),\n",
    "    dropdown,\n",
    "    dcc.Graph(id=\"time-series-chart\"),\n",
    "])\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"time-series-chart\", \"figure\"), \n",
    "    Input(\"ticker\", \"value\"))\n",
    "\n",
    "def display_time_series(ticker):\n",
    "    df_pivot = df.pivot(index='ds', columns='unique_id', values='y')\n",
    "    df_pivot = df_pivot.reset_index()\n",
    "    df_pivot = df_pivot.fillna(0)\n",
    "    \n",
    "    fig = px.line(df_pivot, x='ds', y=ticker, title=ticker, template='plotly_dark')\n",
    "    fig.update_layout(plot_bgcolor='rgba(0, 0, 0, 0)',\n",
    "                      paper_bgcolor='rgba(0, 0, 0, 0)')\n",
    "    \n",
    "    #bandas de percentiles \n",
    "    p_ = all_preds.loc[all_preds['unique_id'] == ticker]\n",
    "    fig.add_trace(go.Scatter(x=p_['ds'], y=p_['p10'], mode='lines', line=dict(color='rgba(255, 165, 0, 0.2)'), name='p10'))\n",
    "    fig.add_trace(go.Scatter(x=p_['ds'], y=p_['p90'], mode='lines', line=dict(color='rgba(255, 165, 0, 0.2)'), name='p90', fill='tonexty', fillcolor='rgba(255, 165, 0, 0.2)'))\n",
    "    fig.add_trace(go.Scatter(x=p_['ds'], y=p_['p25'], mode='lines', line=dict(color='orange'), name='p25'))\n",
    "    fig.add_trace(go.Scatter(x=p_['ds'], y=p_['p75'], mode='lines', line=dict(color='orange'), name='p75', fill='tonexty', fillcolor='rgba(255, 165, 0, 0.2)'))\n",
    "    fig.add_trace(go.Scatter(x=p_['ds'], y=p_['pred'], mode='lines', line=dict(color='orange'), name='Forecast'))\n",
    "    return fig\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run_server(debug=True, port=8080, mode='inline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Guardamos las métricas para cada una de las series__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_tbl=guardar_metricas(comparison_tbl, all_preds, exetime, 'Glounts Deep AR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serie</th>\n",
       "      <th>Modelo</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>sMAPE</th>\n",
       "      <th>Processing Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>expo_1</td>\n",
       "      <td>Glounts Deep AR</td>\n",
       "      <td>1703.796685</td>\n",
       "      <td>1846.028377</td>\n",
       "      <td>0.962050</td>\n",
       "      <td>1172.6817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>expo_2</td>\n",
       "      <td>Glounts Deep AR</td>\n",
       "      <td>976.128883</td>\n",
       "      <td>1154.407304</td>\n",
       "      <td>1.644388</td>\n",
       "      <td>1172.6817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>expo_3</td>\n",
       "      <td>Glounts Deep AR</td>\n",
       "      <td>227.577997</td>\n",
       "      <td>239.319369</td>\n",
       "      <td>0.603835</td>\n",
       "      <td>1172.6817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>expo_4</td>\n",
       "      <td>Glounts Deep AR</td>\n",
       "      <td>62.177777</td>\n",
       "      <td>76.060508</td>\n",
       "      <td>0.612576</td>\n",
       "      <td>1172.6817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>expo_5</td>\n",
       "      <td>Glounts Deep AR</td>\n",
       "      <td>97.412222</td>\n",
       "      <td>108.306678</td>\n",
       "      <td>0.815376</td>\n",
       "      <td>1172.6817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>impo_1</td>\n",
       "      <td>Glounts Deep AR</td>\n",
       "      <td>1034.762234</td>\n",
       "      <td>1117.583146</td>\n",
       "      <td>0.337640</td>\n",
       "      <td>1172.6817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>impo_2</td>\n",
       "      <td>Glounts Deep AR</td>\n",
       "      <td>159.706675</td>\n",
       "      <td>187.804091</td>\n",
       "      <td>0.340565</td>\n",
       "      <td>1172.6817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>impo_3</td>\n",
       "      <td>Glounts Deep AR</td>\n",
       "      <td>85.248889</td>\n",
       "      <td>92.986704</td>\n",
       "      <td>1.375873</td>\n",
       "      <td>1172.6817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>impo_4</td>\n",
       "      <td>Glounts Deep AR</td>\n",
       "      <td>49.672222</td>\n",
       "      <td>56.974424</td>\n",
       "      <td>0.748158</td>\n",
       "      <td>1172.6817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>impo_5</td>\n",
       "      <td>Glounts Deep AR</td>\n",
       "      <td>690.743335</td>\n",
       "      <td>1129.498393</td>\n",
       "      <td>0.730922</td>\n",
       "      <td>1172.6817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>impo_6</td>\n",
       "      <td>Glounts Deep AR</td>\n",
       "      <td>352.311113</td>\n",
       "      <td>409.076129</td>\n",
       "      <td>0.469932</td>\n",
       "      <td>1172.6817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>impo_7</td>\n",
       "      <td>Glounts Deep AR</td>\n",
       "      <td>59.914442</td>\n",
       "      <td>81.445910</td>\n",
       "      <td>0.212950</td>\n",
       "      <td>1172.6817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Serie           Modelo          MAE         RMSE     sMAPE  \\\n",
       "83  expo_1  Glounts Deep AR  1703.796685  1846.028377  0.962050   \n",
       "84  expo_2  Glounts Deep AR   976.128883  1154.407304  1.644388   \n",
       "85  expo_3  Glounts Deep AR   227.577997   239.319369  0.603835   \n",
       "86  expo_4  Glounts Deep AR    62.177777    76.060508  0.612576   \n",
       "87  expo_5  Glounts Deep AR    97.412222   108.306678  0.815376   \n",
       "88  impo_1  Glounts Deep AR  1034.762234  1117.583146  0.337640   \n",
       "89  impo_2  Glounts Deep AR   159.706675   187.804091  0.340565   \n",
       "90  impo_3  Glounts Deep AR    85.248889    92.986704  1.375873   \n",
       "91  impo_4  Glounts Deep AR    49.672222    56.974424  0.748158   \n",
       "92  impo_5  Glounts Deep AR   690.743335  1129.498393  0.730922   \n",
       "93  impo_6  Glounts Deep AR   352.311113   409.076129  0.469932   \n",
       "94  impo_7  Glounts Deep AR    59.914442    81.445910  0.212950   \n",
       "\n",
       "   Processing Time  \n",
       "83       1172.6817  \n",
       "84       1172.6817  \n",
       "85       1172.6817  \n",
       "86       1172.6817  \n",
       "87       1172.6817  \n",
       "88       1172.6817  \n",
       "89       1172.6817  \n",
       "90       1172.6817  \n",
       "91       1172.6817  \n",
       "92       1172.6817  \n",
       "93       1172.6817  \n",
       "94       1172.6817  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_tbl.tail(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Glounts Deep AR - Variable exógena"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cotizacion dolar oficial\n",
    "\n",
    "Obtenida de: https://es.investing.com/currencies/usd-ars-historical-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cot_dolar_blue= pd.read_csv('Data/Datos históricos USD_ARSB.csv')\n",
    "df_cot_dolar_blue['Fecha'] = pd.to_datetime(df_cot_dolar_blue['Fecha'], format='%d.%m.%Y')\n",
    "df_cot_dolar_blue= df_cot_dolar_blue[['Fecha','Último']]\n",
    "df_cot_dolar_blue['Último']= df_cot_dolar_blue['Último'].str.replace(',', '.')\n",
    "df_cot_dolar_blue['Último']= df_cot_dolar_blue['Último'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Último</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>2019-02-03</td>\n",
       "      <td>37.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>2019-01-27</td>\n",
       "      <td>37.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>2019-01-20</td>\n",
       "      <td>38.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>2019-01-13</td>\n",
       "      <td>38.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>39.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Fecha  Último\n",
       "208 2019-02-03   37.38\n",
       "209 2019-01-27   37.62\n",
       "210 2019-01-20   38.12\n",
       "211 2019-01-13   38.88\n",
       "212 2019-01-06   39.00"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cot_dolar_blue.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df.merge(df_cot_dolar_blue, left_on='ds', right_on='Fecha', how='left')\n",
    "df_merged = df_merged.rename(columns={'Último': 'cotizacion'}).drop('Fecha', axis=1)\n",
    "df_merged['cotizacion']=df_merged['cotizacion'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>y</th>\n",
       "      <th>cotizacion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>impo_1</td>\n",
       "      <td>1950</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-13</td>\n",
       "      <td>impo_1</td>\n",
       "      <td>2402</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-20</td>\n",
       "      <td>impo_1</td>\n",
       "      <td>2782</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-27</td>\n",
       "      <td>impo_1</td>\n",
       "      <td>3263</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-02-03</td>\n",
       "      <td>impo_1</td>\n",
       "      <td>3843</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ds unique_id     y  cotizacion\n",
       "0 2019-01-06    impo_1  1950          39\n",
       "1 2019-01-13    impo_1  2402          38\n",
       "2 2019-01-20    impo_1  2782          38\n",
       "3 2019-01-27    impo_1  3263          37\n",
       "4 2019-02-03    impo_1  3843          37"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Definimos el set de train y test__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train= df_merged\n",
    "valid = df_merged[df_merged['ds'] >= '2022-11-01']\n",
    "\n",
    "#cuando agregamos una variable exogena la misma debe ser input en la fase de test, es decir debe ser una variable conocida a futuro.\n",
    "#Aunque en la practica es casi inviable conocer la cotizacion del dolar a futuro se podria crear un segundo modelo que prediga la misma, \n",
    "#pero en esta instancia a modo de prueba correre el modelo bajo el supuesto que podremos agregar la cotizacion del dolar futuro en el modelo \n",
    "#una vez que este en produccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = PandasDataset.from_long_dataframe(train,\n",
    "                                             target='y', \n",
    "                                             item_id='unique_id', \n",
    "                                             timestamp='ds',\n",
    "                                             freq='W', \n",
    "                                             feat_dynamic_real=['cotizacion']) #agregamos la variable exogena \n",
    "#future_lenght = 10 \n",
    "#pasarle al train todo el dataset, la variable target hasta el 1 de noviembre, y necesitos 10 valores de cot hacia el futuro \n",
    "#como es autoregresivo necesita los valores futuros, valor del dolar hasta hoy \n",
    "#prediga las dos variables -> deep VAR -> predecir las dos cosas, target + exogenas => estimar por fuera el dolar -> input nuevo modelo \n",
    "#hacer la prueba si realmente mejora evaluar las opciones => el valor observado futuro nunca lo voy a tener -> valor estimado != valor futuro \n",
    "#variable categorica estatica => pais de origen del motivo -> USA, EUROPA, CHINA etc -> static categorical no varia en el tiempo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Definicion del Modelo DeepAr - feat dynamic real__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\Bravo15\\anaconda3\\envs\\modelling-torch\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:108: PossibleUserWarning:\n",
      "\n",
      "You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "\n",
      "\n",
      "  | Name  | Type        | Params | In sizes | Out sizes  \n",
      "---------------------------------------------------------------\n",
      "0 | model | DeepARModel | 50.2 K | ?        | [1, 100, 9]\n",
      "---------------------------------------------------------------\n",
      "50.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "50.2 K    Total params\n",
      "0.201     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5edac546f5d74b6096ddde2923d7f048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 11.26441 (best 11.26441), saving model to 'c:\\\\Users\\\\Bravo15\\\\Desktop\\\\raico\\\\Proyecto final\\\\Project_Raiconet_101\\\\Experiments\\\\lightning_logs\\\\version_9\\\\checkpoints\\\\epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 8.38437 (best 8.38437), saving model to 'c:\\\\Users\\\\Bravo15\\\\Desktop\\\\raico\\\\Proyecto final\\\\Project_Raiconet_101\\\\Experiments\\\\lightning_logs\\\\version_9\\\\checkpoints\\\\epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' was not in top 1\n",
      "Epoch 3, global step 200: 'train_loss' was not in top 1\n",
      "Epoch 4, global step 250: 'train_loss' was not in top 1\n",
      "Epoch 5, global step 300: 'train_loss' was not in top 1\n",
      "Epoch 6, global step 350: 'train_loss' was not in top 1\n",
      "Epoch 7, global step 400: 'train_loss' was not in top 1\n",
      "Epoch 8, global step 450: 'train_loss' was not in top 1\n",
      "Epoch 9, global step 500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "tic = time.clock()\n",
    "estimator2 = DeepAREstimator(freq='W', #la frecuencia de los datos es semanal por lo que el modelo debe ser semanal tambien\n",
    "                            context_length=9, # el modelo va a usar las ultimas 9 semanas para predecir la siguientes 10\n",
    "                            prediction_length=9, # va a predecir las proximas 9 semanas \n",
    "                            num_layers=4, #el modelo posee 4 capas con un default de 40 nodos por capa \n",
    "                            dropout_rate= 0.2, #seteo de 20% de las units en una layer en cero de forma random, el default es 0.1\n",
    "                            trainer_kwargs={ 'max_epochs':10},#120, #en vez de poner un early stopping defino un max epoch de 30 ((210)\n",
    "                            num_feat_dynamic_real= int(1), \n",
    "                            distr_output= NegativeBinomialOutput())  #el default es Distribucion t-student, pero al usar negative binomial permite que las predicciones no tomen valores negativos\n",
    "\n",
    "predictor2 = estimator2.train(train_ds, num_workers=2)\n",
    "\n",
    "toc =  time.clock() #frenamos el cronometro y a continuacion creamos la variable que guarda el tiempo transcurrido desde que empezo a correr el modelo hasta q termino\n",
    "exetime = '{0:.4f}'.format(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_it, ts_it = make_evaluation_predictions(\n",
    "    dataset=train_ds,  \n",
    "    predictor=predictor2, \n",
    ")\n",
    "\n",
    "tss = list(ts_it)\n",
    "forecasts = list(forecast_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>y</th>\n",
       "      <th>cotizacion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2022-11-06</td>\n",
       "      <td>impo_1</td>\n",
       "      <td>3067</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>2022-11-13</td>\n",
       "      <td>impo_1</td>\n",
       "      <td>2557</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>2022-11-20</td>\n",
       "      <td>impo_1</td>\n",
       "      <td>1651</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>2022-11-27</td>\n",
       "      <td>impo_1</td>\n",
       "      <td>2538</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>2022-12-04</td>\n",
       "      <td>impo_1</td>\n",
       "      <td>2321</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ds unique_id     y  cotizacion\n",
       "200 2022-11-06    impo_1  3067         291\n",
       "201 2022-11-13    impo_1  2557         304\n",
       "202 2022-11-20    impo_1  1651         318\n",
       "203 2022-11-27    impo_1  2538         310\n",
       "204 2022-12-04    impo_1  2321         314"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5497150430545928"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds2 = list()\n",
    "for item in forecasts:\n",
    "    unique_id = item.item_id\n",
    "    p = item.samples.mean(axis=0)\n",
    "    p10 = np.percentile(item.samples, 10, axis=0)\n",
    "    p90 = np.percentile(item.samples, 90, axis=0)\n",
    "    p25 = np.percentile(item.samples, 25, axis=0)\n",
    "    p75 = np.percentile(item.samples, 75, axis=0)\n",
    "    dates = pd.date_range(start=item.start_date.to_timestamp(), periods=len(p), freq='W')\n",
    "    family_pred = pd.DataFrame({'ds': dates, \n",
    "                                'unique_id': unique_id,\n",
    "                                'pred': p,\n",
    "                                'p25': p25,\n",
    "                                'p75': p75,\n",
    "                                'p10': p10, \n",
    "                                'p90': p90})\n",
    "    all_preds2 += [family_pred]\n",
    "all_preds2 = pd.concat(all_preds2, ignore_index=True)\n",
    "all_preds2 = all_preds2.merge(valid, on=['ds', 'unique_id'], how='left')\n",
    "\n",
    "all_preds2.dropna(inplace=True)\n",
    "\n",
    "Metrics(all_preds2['y'], all_preds2['pred']).wmape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Resultados Obtenidos: Deep AR - feat dynamic real__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1a98819e740>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "app2 = Dash(external_stylesheets=[dbc.themes.SLATE])\n",
    "\n",
    "\n",
    "dropdown = dcc.Dropdown(\n",
    "    id=\"ticker\",\n",
    "    options=[{\"label\": unique_id, \"value\": unique_id} for unique_id in df[\"unique_id\"].unique()],\n",
    "    value=\"impo_1\",\n",
    "    clearable=False, \n",
    "    style={'background-color': 'grey'}\n",
    ")\n",
    "\n",
    "app2.layout = html.Div([\n",
    "    html.H4('Deep AR - Feat dynamic real Resultados'),\n",
    "    html.P(\"Seleccionar motivo:\"),\n",
    "    dropdown,\n",
    "    dcc.Graph(id=\"time-series-chart\"),\n",
    "])\n",
    "\n",
    "\n",
    "@app2.callback(\n",
    "    Output(\"time-series-chart\", \"figure\"), \n",
    "    Input(\"ticker\", \"value\"))\n",
    "\n",
    "def display_time_series(ticker):\n",
    "    df_pivot = df.pivot(index='ds', columns='unique_id', values='y')\n",
    "    df_pivot = df_pivot.reset_index()\n",
    "    df_pivot = df_pivot.fillna(0)\n",
    "    \n",
    "    fig = px.line(df_pivot, x='ds', y=ticker, title=ticker, template='plotly_dark')\n",
    "    fig.update_layout(plot_bgcolor='rgba(0, 0, 0, 0)',\n",
    "                      paper_bgcolor='rgba(0, 0, 0, 0)')\n",
    "    \n",
    "    #bandas de percentiles \n",
    "    p_ = all_preds2.loc[all_preds2['unique_id'] == ticker]\n",
    "    fig.add_trace(go.Scatter(x=p_['ds'], y=p_['p10'], mode='lines', line=dict(color='rgba(255, 165, 0, 0.2)'), name='p10'))\n",
    "    fig.add_trace(go.Scatter(x=p_['ds'], y=p_['p90'], mode='lines', line=dict(color='rgba(255, 165, 0, 0.2)'), name='p90', fill='tonexty', fillcolor='rgba(255, 165, 0, 0.2)'))\n",
    "    fig.add_trace(go.Scatter(x=p_['ds'], y=p_['p25'], mode='lines', line=dict(color='orange'), name='p25'))\n",
    "    fig.add_trace(go.Scatter(x=p_['ds'], y=p_['p75'], mode='lines', line=dict(color='orange'), name='p75', fill='tonexty', fillcolor='rgba(255, 165, 0, 0.2)'))\n",
    "    fig.add_trace(go.Scatter(x=p_['ds'], y=p_['pred'], mode='lines', line=dict(color='orange'), name='Forecast'))\n",
    "    return fig\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app2.run_server(debug=True, port=8081, mode='inline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Guardamos las métricas para cada una de las series__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_tbl=guardar_metricas(comparison_tbl, all_preds, exetime, 'Glounts Deep AR feat dynamic variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serie</th>\n",
       "      <th>Modelo</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>sMAPE</th>\n",
       "      <th>Processing Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>expo_1</td>\n",
       "      <td>Glounts Deep AR feat dynamic variable</td>\n",
       "      <td>1703.796685</td>\n",
       "      <td>1846.028377</td>\n",
       "      <td>0.962050</td>\n",
       "      <td>72.3568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>expo_2</td>\n",
       "      <td>Glounts Deep AR feat dynamic variable</td>\n",
       "      <td>976.128883</td>\n",
       "      <td>1154.407304</td>\n",
       "      <td>1.644388</td>\n",
       "      <td>72.3568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>expo_3</td>\n",
       "      <td>Glounts Deep AR feat dynamic variable</td>\n",
       "      <td>227.577997</td>\n",
       "      <td>239.319369</td>\n",
       "      <td>0.603835</td>\n",
       "      <td>72.3568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>expo_4</td>\n",
       "      <td>Glounts Deep AR feat dynamic variable</td>\n",
       "      <td>62.177777</td>\n",
       "      <td>76.060508</td>\n",
       "      <td>0.612576</td>\n",
       "      <td>72.3568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>expo_5</td>\n",
       "      <td>Glounts Deep AR feat dynamic variable</td>\n",
       "      <td>97.412222</td>\n",
       "      <td>108.306678</td>\n",
       "      <td>0.815376</td>\n",
       "      <td>72.3568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>impo_1</td>\n",
       "      <td>Glounts Deep AR feat dynamic variable</td>\n",
       "      <td>1034.762234</td>\n",
       "      <td>1117.583146</td>\n",
       "      <td>0.337640</td>\n",
       "      <td>72.3568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>impo_2</td>\n",
       "      <td>Glounts Deep AR feat dynamic variable</td>\n",
       "      <td>159.706675</td>\n",
       "      <td>187.804091</td>\n",
       "      <td>0.340565</td>\n",
       "      <td>72.3568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>impo_3</td>\n",
       "      <td>Glounts Deep AR feat dynamic variable</td>\n",
       "      <td>85.248889</td>\n",
       "      <td>92.986704</td>\n",
       "      <td>1.375873</td>\n",
       "      <td>72.3568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>impo_4</td>\n",
       "      <td>Glounts Deep AR feat dynamic variable</td>\n",
       "      <td>49.672222</td>\n",
       "      <td>56.974424</td>\n",
       "      <td>0.748158</td>\n",
       "      <td>72.3568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>impo_5</td>\n",
       "      <td>Glounts Deep AR feat dynamic variable</td>\n",
       "      <td>690.743335</td>\n",
       "      <td>1129.498393</td>\n",
       "      <td>0.730922</td>\n",
       "      <td>72.3568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>impo_6</td>\n",
       "      <td>Glounts Deep AR feat dynamic variable</td>\n",
       "      <td>352.311113</td>\n",
       "      <td>409.076129</td>\n",
       "      <td>0.469932</td>\n",
       "      <td>72.3568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>impo_7</td>\n",
       "      <td>Glounts Deep AR feat dynamic variable</td>\n",
       "      <td>59.914442</td>\n",
       "      <td>81.445910</td>\n",
       "      <td>0.212950</td>\n",
       "      <td>72.3568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Serie                                 Modelo          MAE         RMSE  \\\n",
       "95   expo_1  Glounts Deep AR feat dynamic variable  1703.796685  1846.028377   \n",
       "96   expo_2  Glounts Deep AR feat dynamic variable   976.128883  1154.407304   \n",
       "97   expo_3  Glounts Deep AR feat dynamic variable   227.577997   239.319369   \n",
       "98   expo_4  Glounts Deep AR feat dynamic variable    62.177777    76.060508   \n",
       "99   expo_5  Glounts Deep AR feat dynamic variable    97.412222   108.306678   \n",
       "100  impo_1  Glounts Deep AR feat dynamic variable  1034.762234  1117.583146   \n",
       "101  impo_2  Glounts Deep AR feat dynamic variable   159.706675   187.804091   \n",
       "102  impo_3  Glounts Deep AR feat dynamic variable    85.248889    92.986704   \n",
       "103  impo_4  Glounts Deep AR feat dynamic variable    49.672222    56.974424   \n",
       "104  impo_5  Glounts Deep AR feat dynamic variable   690.743335  1129.498393   \n",
       "105  impo_6  Glounts Deep AR feat dynamic variable   352.311113   409.076129   \n",
       "106  impo_7  Glounts Deep AR feat dynamic variable    59.914442    81.445910   \n",
       "\n",
       "        sMAPE Processing Time  \n",
       "95   0.962050         72.3568  \n",
       "96   1.644388         72.3568  \n",
       "97   0.603835         72.3568  \n",
       "98   0.612576         72.3568  \n",
       "99   0.815376         72.3568  \n",
       "100  0.337640         72.3568  \n",
       "101  0.340565         72.3568  \n",
       "102  1.375873         72.3568  \n",
       "103  0.748158         72.3568  \n",
       "104  0.730922         72.3568  \n",
       "105  0.469932         72.3568  \n",
       "106  0.212950         72.3568  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_tbl.tail(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**  A pesar de agregar la variable exogena del tipo de cambio, aunque los resultados del modelo no mejoran y aun el modelo Glounts Deep AR permite obtener mejores predicciones. Comparando los resultados entre el primer modelo Deep Ar y el segundo Deep Ar con feat dynamic real, se observa que ambos no logran captar las tendencias y cambios drasticos existentes en los datos. Si bien los resultados son mejores que los obtenidos con los modelos clasicos, los modelos de machine learning con entrenamiento global poseen mejores metricas, aun asi el modelo permite obtener predicciones con cierto margen de error pero aun no logra captar los cambios abruptos que poseen las series. En gran medida se debe a la naturaleza del modelo Deep AR, ya que como su nombre indica al ser un modelo autoregresivo busca patrones en valores historicos de la serie buscando hacer inferencias con distribuciones conocidas. Pero aun asi, como los datos presentes son erraticos y no revelan una distribucion aparente este tipo de modelo no parece ser suficiente. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modelling-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
